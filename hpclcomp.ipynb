{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-04T07:24:53.467876Z","iopub.status.busy":"2024-04-04T07:24:53.467447Z","iopub.status.idle":"2024-04-04T07:24:53.474347Z","shell.execute_reply":"2024-04-04T07:24:53.473410Z","shell.execute_reply.started":"2024-04-04T07:24:53.467844Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T07:56:22.758126Z","iopub.status.busy":"2024-04-04T07:56:22.757733Z","iopub.status.idle":"2024-04-04T07:56:23.140705Z","shell.execute_reply":"2024-04-04T07:56:23.139518Z","shell.execute_reply.started":"2024-04-04T07:56:22.758094Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["          Date   Time CustomerID  Location  Total Fuel  Fuel_1  Fuel_2  \\\n","0   2024-02-20  17:40      14007        14          24      24       0   \n","1   2023-06-18  08:15      01006         1          24      24       0   \n","2   2023-07-19  11:45      03009         3          12       3       3   \n","3   2023-05-15  08:15      11002        11          12       0       3   \n","4   2022-06-10  17:40      04003         4          12       6       0   \n","..         ...    ...        ...       ...         ...     ...     ...   \n","699 2023-09-09  11:45      07001         7          12       6       4   \n","700 2022-06-06  08:15      15007        15          12       3       6   \n","701 2023-01-30  11:45      05002         5          12      12       0   \n","702 2023-08-14  16:20      14009        14          24      16       3   \n","703 2022-11-05  13:00      04002         4          12       6       3   \n","\n","     Fuel_3  Fuel_4  Fuel_5  Fuel_6  \n","0         0       0       0       0  \n","1         0       0       0       0  \n","2         4       0       0       0  \n","3         3       4       0       0  \n","4         6       0       0       0  \n","..      ...     ...     ...     ...  \n","699       0       0       0       0  \n","700       3       0       0       0  \n","701       0       0       0       0  \n","702       4       0       0       0  \n","703       0       0       0       0  \n","\n","[704 rows x 11 columns]\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import random\n","\n","# Function to generate random fuel distribution satisfying constraints\n","# Function to generate random fuel distribution satisfying constraints\n","def generate_fuel_distribution(total_fuel):\n","    # Initialize the fuel distribution list\n","    fuel_distribution = [0] * 6\n","    \n","    # Generate fuel amounts that are multiples of either 4 or 3\n","    for i in range(6):\n","        # Generate a random fuel amount\n","        fuel = np.random.choice(range(total_fuel + 1))\n","        \n","        # Ensure the fuel amount is a multiple of either 4 or 3\n","        while fuel % 4 != 0 and fuel % 3 != 0:\n","            fuel = np.random.choice(range(total_fuel + 1))\n","        \n","        fuel_distribution[i] = fuel\n","        total_fuel -= fuel\n","    \n","    return fuel_distribution\n","\n","# Generate sample dataset\n","def generate_sample_dataset(num_locations, customers_per_location):\n","    data = []\n","    for location in range(1, num_locations + 1):\n","        for customer in range(1, customers_per_location + 1):\n","            num_orders = random.randint(1, 8)  # Randomly select number of orders\n","            for _ in range(num_orders):\n","                #date =  \"04-04-2024\"\n","\n","\n","                current_date = pd.Timestamp.now().date()\n","\n","                # Define the start date as two years ago from the current date\n","                start_date = current_date - pd.DateOffset(years=2)\n","\n","                # Define the end date as yesterday to ensure that the last two years are included\n","                end_date = current_date - pd.DateOffset(days=1)\n","\n","                # Generate a random date between start_date and end_date\n","                date = pd.Timestamp(start_date + pd.Timedelta(days=np.random.randint((end_date - start_date).days)))\n","\n","                time = random.choice(['08:15', '09:30', '11:45', '13:00', '16:20', '17:40'])\n","                customer_id = str(location).zfill(2) + str(customer).zfill(3)  # Unique customer IDs based on location\n","                total_fuel = random.choice([12, 24])\n","                fuel_distribution = generate_fuel_distribution(total_fuel)\n","                data.append([date, time, customer_id, location, total_fuel] + list(fuel_distribution))\n","    columns = ['Date', 'Time', 'CustomerID', 'Location', 'Total Fuel', 'Fuel_1', 'Fuel_2', 'Fuel_3', 'Fuel_4', 'Fuel_5', 'Fuel_6']\n","    return pd.DataFrame(data, columns=columns)\n","\n","# Generate sample dataset with 30 locations, 10 customers per location, and variable number of orders\n","sample_data = generate_sample_dataset(15, 10)\n","\n","# Shuffle the dataset\n","sample_data = sample_data.sample(frac=1).reset_index(drop=True)\n","\n","# Save sample dataset to CSV file\n","sample_data.to_csv('sample_dataset.csv', index=False)\n","\n","# Display sample dataset\n","print(sample_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(np.unique(sample_data[\"CustomerID\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_data.to_csv('sample_dataset.csv', index=False)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T07:57:15.493307Z","iopub.status.busy":"2024-04-04T07:57:15.492850Z","iopub.status.idle":"2024-04-04T07:57:49.862875Z","shell.execute_reply":"2024-04-04T07:57:49.861553Z","shell.execute_reply.started":"2024-04-04T07:57:15.493233Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-04 07:57:19.790026: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-04 07:57:19.790165: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-04 07:57:19.997541: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 355.7877 - val_loss: 349.8616\n","Epoch 2/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 363.1908 - val_loss: 345.7569\n","Epoch 3/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 350.6413 - val_loss: 339.5614\n","Epoch 4/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 349.1295 - val_loss: 330.4029\n","Epoch 5/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 329.7110 - val_loss: 318.0803\n","Epoch 6/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 321.2045 - val_loss: 302.1480\n","Epoch 7/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 291.8257 - val_loss: 282.7787\n","Epoch 8/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 274.6163 - val_loss: 259.6769\n","Epoch 9/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 257.2163 - val_loss: 233.7383\n","Epoch 10/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 224.9709 - val_loss: 206.1861\n","Epoch 11/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 194.9309 - val_loss: 178.2029\n","Epoch 12/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 180.8730 - val_loss: 151.2375\n","Epoch 13/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150.5592 - val_loss: 127.2512\n","Epoch 14/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 120.3453 - val_loss: 106.8584\n","Epoch 15/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 104.6024 - val_loss: 91.3828\n","Epoch 16/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 86.7405 - val_loss: 80.7214\n","Epoch 17/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 84.8743 - val_loss: 73.4288\n","Epoch 18/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 73.0297 - val_loss: 69.4188\n","Epoch 19/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 73.8605 - val_loss: 66.9389\n","Epoch 20/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 72.0518 - val_loss: 65.5271\n","Epoch 21/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 66.0127 - val_loss: 64.6280\n","Epoch 22/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 64.7256 - val_loss: 64.0260\n","Epoch 23/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 64.9002 - val_loss: 63.6246\n","Epoch 24/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 69.3084 - val_loss: 63.2918\n","Epoch 25/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 67.0267 - val_loss: 62.8856\n","Epoch 26/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 67.7047 - val_loss: 62.5194\n","Epoch 27/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 62.6609 - val_loss: 62.1661\n","Epoch 28/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.0165 - val_loss: 61.8262\n","Epoch 29/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.3975 - val_loss: 61.5324\n","Epoch 30/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63.8265 - val_loss: 61.1510\n","Epoch 31/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 66.8104 - val_loss: 60.7605\n","Epoch 32/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 64.1603 - val_loss: 60.4146\n","Epoch 33/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 68.2670 - val_loss: 60.0371\n","Epoch 34/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.9386 - val_loss: 59.6822\n","Epoch 35/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.5006 - val_loss: 59.3663\n","Epoch 36/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 66.2693 - val_loss: 58.9961\n","Epoch 37/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.6163 - val_loss: 58.6362\n","Epoch 38/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.8611 - val_loss: 58.2397\n","Epoch 39/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63.6243 - val_loss: 57.8630\n","Epoch 40/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.6541 - val_loss: 57.5356\n","Epoch 41/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.3834 - val_loss: 57.1234\n","Epoch 42/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 62.4413 - val_loss: 56.7449\n","Epoch 43/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.6068 - val_loss: 56.3266\n","Epoch 44/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.5948 - val_loss: 55.8862\n","Epoch 45/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 62.1797 - val_loss: 55.4949\n","Epoch 46/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 61.4047 - val_loss: 55.0556\n","Epoch 47/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 56.0845 - val_loss: 54.7154\n","Epoch 48/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.2535 - val_loss: 54.2137\n","Epoch 49/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 53.2194 - val_loss: 53.7915\n","Epoch 50/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.4196 - val_loss: 53.3561\n","Epoch 1/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0573 - val_loss: 0.0487\n","Epoch 2/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0464 - val_loss: 0.0388\n","Epoch 3/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0360 - val_loss: 0.0333\n","Epoch 4/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0321\n","Epoch 5/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0328 - val_loss: 0.0319\n","Epoch 6/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0325 - val_loss: 0.0317\n","Epoch 7/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0313 - val_loss: 0.0316\n","Epoch 8/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.0315\n","Epoch 9/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.0313\n","Epoch 10/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0312\n","Epoch 11/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0296 - val_loss: 0.0312\n","Epoch 12/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0301 - val_loss: 0.0310\n","Epoch 13/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0310\n","Epoch 14/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0294 - val_loss: 0.0309\n","Epoch 15/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.0309\n","Epoch 16/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0304 - val_loss: 0.0308\n","Epoch 17/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0308\n","Epoch 18/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0293 - val_loss: 0.0308\n","Epoch 19/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0297 - val_loss: 0.0307\n","Epoch 20/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.0309\n","Epoch 21/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0306 - val_loss: 0.0307\n","Epoch 22/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0300 - val_loss: 0.0308\n","Epoch 23/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.0307\n","Epoch 24/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.0308\n","Epoch 25/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0307\n","Epoch 26/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0296 - val_loss: 0.0307\n","Epoch 27/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0297 - val_loss: 0.0308\n","Epoch 28/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0286 - val_loss: 0.0308\n","Epoch 29/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.0308\n","Epoch 30/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0311 - val_loss: 0.0308\n","Epoch 31/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.0308\n","Epoch 32/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0294 - val_loss: 0.0308\n","Epoch 33/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0291 - val_loss: 0.0308\n","Epoch 34/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.0308\n","Epoch 35/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.0308\n","Epoch 36/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0326 - val_loss: 0.0308\n","Epoch 37/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0306 - val_loss: 0.0308\n","Epoch 38/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0289 - val_loss: 0.0309\n","Epoch 39/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.0308\n","Epoch 40/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0309 - val_loss: 0.0308\n","Epoch 41/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0289 - val_loss: 0.0309\n","Epoch 42/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.0309\n","Epoch 43/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0298 - val_loss: 0.0308\n","Epoch 44/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0297 - val_loss: 0.0309\n","Epoch 45/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0294 - val_loss: 0.0308\n","Epoch 46/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0300 - val_loss: 0.0309\n","Epoch 47/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0285 - val_loss: 0.0309\n","Epoch 48/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0294 - val_loss: 0.0309\n","Epoch 49/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.0309\n","Epoch 50/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.0309\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.6114 \n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0321 \n","Mean Squared Error (Total Fuel): 53.356056213378906\n","Mean Squared Error (Fuel Distribution): 0.030935442075133324\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense\n","\n","# Load dataset\n","data = pd.read_csv('sample_dataset.csv')\n","\n","# Convert date and time to datetime format\n","data['Date'] = pd.to_datetime(data['Date'] + ' ' + data['Time'])\n","\n","# Extract features\n","data['DayOfWeek'] = data['Date'].dt.dayofweek\n","data['Month'] = data['Date'].dt.month\n","data['Hour'] = data['Date'].dt.hour\n","data['Minute'] = data['Date'].dt.minute\n","\n","# Normalize numerical features\n","scaler = MinMaxScaler()\n","data[['DayOfWeek', 'Month', 'Hour', 'Minute', 'Fuel_1', 'Fuel_2', 'Fuel_3', 'Fuel_4', 'Fuel_5', 'Fuel_6']] = scaler.fit_transform(data[['DayOfWeek', 'Month', 'Hour', 'Minute', 'Fuel_1', 'Fuel_2', 'Fuel_3', 'Fuel_4', 'Fuel_5', 'Fuel_6']])\n","\n","# Define features and target\n","X = data[['DayOfWeek', 'Month', 'Hour', 'Minute']].values\n","y_total = data['Total Fuel'].values\n","y_distribution = data[['Fuel_1', 'Fuel_2', 'Fuel_3', 'Fuel_4', 'Fuel_5', 'Fuel_6']].values\n","\n","# Split data into train and test sets\n","X_train, X_test, y_train_total, y_test_total, y_train_distribution, y_test_distribution = train_test_split(X, y_total, y_distribution, test_size=0.2, shuffle=False)\n","\n","# Reshape input data for LSTM\n","X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n","X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n","\n","# Define LSTM model for total fuel demand prediction\n","model_total = Sequential()\n","model_total.add(LSTM(units=50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n","model_total.add(Dense(units=1))\n","model_total.compile(optimizer='adam', loss='mse')\n","\n","# Train the model for total fuel demand prediction\n","history_total = model_total.fit(X_train, y_train_total, epochs=50, batch_size=32, validation_data=(X_test, y_test_total), verbose=1)\n","\n","# Define LSTM model for fuel distribution prediction\n","model_distribution = Sequential()\n","model_distribution.add(LSTM(units=50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n","model_distribution.add(Dense(units=6))  # Output 6 values, one for each fuel type\n","model_distribution.compile(optimizer='adam', loss='mse')\n","\n","# Train the model for fuel distribution prediction\n","history_distribution = model_distribution.fit(X_train, y_train_distribution, epochs=50, batch_size=32, validation_data=(X_test, y_test_distribution), verbose=1)\n","\n","# Evaluate the models\n","mse_total = model_total.evaluate(X_test, y_test_total)\n","mse_distribution = model_distribution.evaluate(X_test, y_test_distribution)\n","print(\"Mean Squared Error (Total Fuel):\", mse_total)\n","print(\"Mean Squared Error (Fuel Distribution):\", mse_distribution)\n","\n","# Make predictions\n","predictions_total = model_total.predict(X_test)\n","predictions_distribution = model_distribution.predict(X_test)\n","\n","# Visualize predictions vs actual values\n","# (You can use matplotlib or any other visualization library for this)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T08:01:39.324410Z","iopub.status.busy":"2024-04-04T08:01:39.323871Z","iopub.status.idle":"2024-04-04T08:01:48.822382Z","shell.execute_reply":"2024-04-04T08:01:48.821119Z","shell.execute_reply.started":"2024-04-04T08:01:39.324373Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.4916 - loss: 0.6945 - val_accuracy: 0.4681 - val_loss: 0.6947\n","Epoch 2/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5149 - loss: 0.6920 - val_accuracy: 0.4894 - val_loss: 0.6944\n","Epoch 3/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4884 - loss: 0.6930 - val_accuracy: 0.4894 - val_loss: 0.6941\n","Epoch 4/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5141 - loss: 0.6928 - val_accuracy: 0.4397 - val_loss: 0.6940\n","Epoch 5/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5374 - loss: 0.6919 - val_accuracy: 0.4539 - val_loss: 0.6941\n","Epoch 6/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5083 - loss: 0.6921 - val_accuracy: 0.4610 - val_loss: 0.6941\n","Epoch 7/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5018 - loss: 0.6922 - val_accuracy: 0.4681 - val_loss: 0.6942\n","Epoch 8/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5088 - loss: 0.6928 - val_accuracy: 0.4681 - val_loss: 0.6943\n","Epoch 9/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5374 - loss: 0.6917 - val_accuracy: 0.4610 - val_loss: 0.6943\n","Epoch 10/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5518 - loss: 0.6915 - val_accuracy: 0.4752 - val_loss: 0.6943\n","Epoch 11/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5566 - loss: 0.6919 - val_accuracy: 0.4894 - val_loss: 0.6945\n","Epoch 12/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5587 - loss: 0.6921 - val_accuracy: 0.4894 - val_loss: 0.6945\n","Epoch 13/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5714 - loss: 0.6913 - val_accuracy: 0.4681 - val_loss: 0.6946\n","Epoch 14/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5499 - loss: 0.6913 - val_accuracy: 0.4823 - val_loss: 0.6945\n","Epoch 15/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5305 - loss: 0.6934 - val_accuracy: 0.4681 - val_loss: 0.6948\n","Epoch 16/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5417 - loss: 0.6915 - val_accuracy: 0.4681 - val_loss: 0.6949\n","Epoch 17/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5442 - loss: 0.6903 - val_accuracy: 0.4894 - val_loss: 0.6950\n","Epoch 18/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5265 - loss: 0.6908 - val_accuracy: 0.4610 - val_loss: 0.6952\n","Epoch 19/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5438 - loss: 0.6904 - val_accuracy: 0.4894 - val_loss: 0.6952\n","Epoch 20/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5533 - loss: 0.6895 - val_accuracy: 0.4610 - val_loss: 0.6954\n","Epoch 21/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4952 - loss: 0.6924 - val_accuracy: 0.4539 - val_loss: 0.6957\n","Epoch 22/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4932 - loss: 0.6921 - val_accuracy: 0.4610 - val_loss: 0.6957\n","Epoch 23/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5134 - loss: 0.6917 - val_accuracy: 0.4610 - val_loss: 0.6958\n","Epoch 24/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5250 - loss: 0.6919 - val_accuracy: 0.4681 - val_loss: 0.6959\n","Epoch 25/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5681 - loss: 0.6884 - val_accuracy: 0.4681 - val_loss: 0.6961\n","Epoch 26/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5034 - loss: 0.6926 - val_accuracy: 0.4681 - val_loss: 0.6963\n","Epoch 27/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5447 - loss: 0.6894 - val_accuracy: 0.4681 - val_loss: 0.6963\n","Epoch 28/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5315 - loss: 0.6911 - val_accuracy: 0.4681 - val_loss: 0.6966\n","Epoch 29/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5177 - loss: 0.6913 - val_accuracy: 0.4823 - val_loss: 0.6965\n","Epoch 30/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5362 - loss: 0.6896 - val_accuracy: 0.4681 - val_loss: 0.6966\n","Epoch 31/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5247 - loss: 0.6912 - val_accuracy: 0.4610 - val_loss: 0.6967\n","Epoch 32/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5438 - loss: 0.6884 - val_accuracy: 0.4681 - val_loss: 0.6969\n","Epoch 33/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5492 - loss: 0.6882 - val_accuracy: 0.4681 - val_loss: 0.6971\n","Epoch 34/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5268 - loss: 0.6898 - val_accuracy: 0.4610 - val_loss: 0.6970\n","Epoch 35/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5723 - loss: 0.6876 - val_accuracy: 0.4752 - val_loss: 0.6970\n","Epoch 36/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5347 - loss: 0.6893 - val_accuracy: 0.4681 - val_loss: 0.6972\n","Epoch 37/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5272 - loss: 0.6904 - val_accuracy: 0.4681 - val_loss: 0.6973\n","Epoch 38/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5023 - loss: 0.6917 - val_accuracy: 0.4610 - val_loss: 0.6972\n","Epoch 39/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5237 - loss: 0.6897 - val_accuracy: 0.4610 - val_loss: 0.6975\n","Epoch 40/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5412 - loss: 0.6892 - val_accuracy: 0.4752 - val_loss: 0.6974\n","Epoch 41/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5411 - loss: 0.6894 - val_accuracy: 0.4752 - val_loss: 0.6979\n","Epoch 42/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5526 - loss: 0.6879 - val_accuracy: 0.4681 - val_loss: 0.6978\n","Epoch 43/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5011 - loss: 0.6936 - val_accuracy: 0.4681 - val_loss: 0.6979\n","Epoch 44/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5169 - loss: 0.6893 - val_accuracy: 0.4752 - val_loss: 0.6981\n","Epoch 45/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5589 - loss: 0.6892 - val_accuracy: 0.4752 - val_loss: 0.6984\n","Epoch 46/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5131 - loss: 0.6913 - val_accuracy: 0.4610 - val_loss: 0.6985\n","Epoch 47/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5417 - loss: 0.6894 - val_accuracy: 0.4752 - val_loss: 0.6984\n","Epoch 48/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5578 - loss: 0.6869 - val_accuracy: 0.4752 - val_loss: 0.6987\n","Epoch 49/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5550 - loss: 0.6878 - val_accuracy: 0.4752 - val_loss: 0.6986\n","Epoch 50/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5125 - loss: 0.6901 - val_accuracy: 0.4752 - val_loss: 0.6987\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4744 - loss: 0.6967 \n","Loss: 0.69870525598526\n","Accuracy: 0.4751773178577423\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense\n","\n","# Load dataset\n","data = pd.read_csv('sample_dataset.csv')\n","\n","# Convert date and time to datetime format\n","data['Date'] = pd.to_datetime(data['Date'] + ' ' + data['Time'])\n","\n","# Extract features\n","data['DayOfWeek'] = data['Date'].dt.dayofweek\n","data['Month'] = data['Date'].dt.month\n","data['Hour'] = data['Date'].dt.hour\n","data['Minute'] = data['Date'].dt.minute\n","\n","# Normalize numerical features\n","scaler = MinMaxScaler()\n","data[['DayOfWeek', 'Month', 'Hour', 'Minute', 'Fuel_1', 'Fuel_2', 'Fuel_3', 'Fuel_4', 'Fuel_5', 'Fuel_6']] = scaler.fit_transform(data[['DayOfWeek', 'Month', 'Hour', 'Minute', 'Fuel_1', 'Fuel_2', 'Fuel_3', 'Fuel_4', 'Fuel_5', 'Fuel_6']])\n","\n","# Define features and target\n","X = data[['DayOfWeek', 'Month', 'Hour', 'Minute']].values\n","y_total = data['Total Fuel'].values\n","\n","# Convert y_total to binary labels\n","y_binary = (y_total == 24).astype(int)\n","\n","# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, shuffle=False)\n","\n","# Reshape input data for LSTM\n","X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n","X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n","\n","# Define LSTM model for total fuel demand classification\n","model = Sequential()\n","model.add(LSTM(units=50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n","model.add(Dense(units=1, activation='sigmoid'))  # Output probability for binary classification\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Use binary cross-entropy loss and accuracy metric\n","\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)\n","\n","# Make predictions\n","predictions_proba = model.predict(X_test)\n","predictions_binary = (predictions_proba > 0.5).astype(int)\n","\n","# Visualize predictions vs actual values\n","# (You can use classification metrics and confusion matrix for evaluation)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T08:02:42.110583Z","iopub.status.busy":"2024-04-04T08:02:42.110099Z","iopub.status.idle":"2024-04-04T08:02:42.122817Z","shell.execute_reply":"2024-04-04T08:02:42.121568Z","shell.execute_reply.started":"2024-04-04T08:02:42.110549Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[0.53768486],\n","       [0.51402575],\n","       [0.5158247 ],\n","       [0.46139425],\n","       [0.47766173],\n","       [0.51296896],\n","       [0.47433767],\n","       [0.48462474],\n","       [0.46367228],\n","       [0.47343493],\n","       [0.5605266 ],\n","       [0.5420498 ],\n","       [0.4681668 ],\n","       [0.44781366],\n","       [0.43916088],\n","       [0.48501638],\n","       [0.4742319 ],\n","       [0.5555755 ],\n","       [0.51244867],\n","       [0.5595331 ],\n","       [0.5555755 ],\n","       [0.4913653 ],\n","       [0.4841042 ],\n","       [0.5300475 ],\n","       [0.511459  ],\n","       [0.5026263 ],\n","       [0.47513908],\n","       [0.4827322 ],\n","       [0.49509165],\n","       [0.4712961 ],\n","       [0.48931402],\n","       [0.574765  ],\n","       [0.46699643],\n","       [0.48565888],\n","       [0.5071384 ],\n","       [0.5269627 ],\n","       [0.5160867 ],\n","       [0.4993001 ],\n","       [0.49018088],\n","       [0.52984416],\n","       [0.5595331 ],\n","       [0.4848653 ],\n","       [0.4827322 ],\n","       [0.57417876],\n","       [0.47993243],\n","       [0.48286134],\n","       [0.5068337 ],\n","       [0.55929184],\n","       [0.4632264 ],\n","       [0.47758558],\n","       [0.5495991 ],\n","       [0.4972143 ],\n","       [0.5191164 ],\n","       [0.5050726 ],\n","       [0.4972143 ],\n","       [0.52987957],\n","       [0.5751969 ],\n","       [0.44097224],\n","       [0.53981894],\n","       [0.49200347],\n","       [0.46578735],\n","       [0.49396423],\n","       [0.5171411 ],\n","       [0.47045296],\n","       [0.49298924],\n","       [0.48766056],\n","       [0.45942643],\n","       [0.521979  ],\n","       [0.503723  ],\n","       [0.4758361 ],\n","       [0.5199992 ],\n","       [0.4836242 ],\n","       [0.49268907],\n","       [0.56046313],\n","       [0.4729534 ],\n","       [0.48326865],\n","       [0.5130979 ],\n","       [0.5006701 ],\n","       [0.47669402],\n","       [0.56021374],\n","       [0.49795794],\n","       [0.488876  ],\n","       [0.47651276],\n","       [0.4833316 ],\n","       [0.48316625],\n","       [0.496972  ],\n","       [0.54560935],\n","       [0.504752  ],\n","       [0.51002043],\n","       [0.47552565],\n","       [0.50003105],\n","       [0.43403652],\n","       [0.5300475 ],\n","       [0.5134033 ],\n","       [0.50159883],\n","       [0.498751  ],\n","       [0.4457839 ],\n","       [0.5097693 ],\n","       [0.4759785 ],\n","       [0.46019903],\n","       [0.57417876],\n","       [0.50155824],\n","       [0.50154   ],\n","       [0.54416466],\n","       [0.47758558],\n","       [0.4663976 ],\n","       [0.4695373 ],\n","       [0.4742449 ],\n","       [0.573418  ],\n","       [0.5160867 ],\n","       [0.5435193 ],\n","       [0.4575262 ],\n","       [0.47513908],\n","       [0.48064354],\n","       [0.45275748],\n","       [0.53042525],\n","       [0.48053664],\n","       [0.47259504],\n","       [0.54336745],\n","       [0.54429436],\n","       [0.4770798 ],\n","       [0.48195502],\n","       [0.47513908],\n","       [0.49355632],\n","       [0.4999756 ],\n","       [0.45413932],\n","       [0.48157734],\n","       [0.48286134],\n","       [0.5223895 ],\n","       [0.50155824],\n","       [0.55406845],\n","       [0.49355632],\n","       [0.47928375],\n","       [0.4870514 ],\n","       [0.46964905],\n","       [0.4957978 ],\n","       [0.49774808],\n","       [0.4548807 ],\n","       [0.4714179 ],\n","       [0.46682212],\n","       [0.53768486]], dtype=float32)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["predictions_proba"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T08:16:55.374320Z","iopub.status.busy":"2024-04-04T08:16:55.373887Z","iopub.status.idle":"2024-04-04T08:17:11.387936Z","shell.execute_reply":"2024-04-04T08:17:11.386778Z","shell.execute_reply.started":"2024-04-04T08:16:55.374287Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.1685 - loss: 30.6286 - val_accuracy: 0.6525 - val_loss: 29.9325\n","Epoch 2/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5557 - loss: 29.9467 - val_accuracy: 0.6525 - val_loss: 28.5034\n","Epoch 3/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5700 - loss: 27.8556 - val_accuracy: 0.6525 - val_loss: 25.8902\n","Epoch 4/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5892 - loss: 25.9868 - val_accuracy: 0.6525 - val_loss: 23.4369\n","Epoch 5/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5986 - loss: 24.5745 - val_accuracy: 0.6525 - val_loss: 22.5429\n","Epoch 6/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6169 - loss: 24.6375 - val_accuracy: 0.6525 - val_loss: 22.4700\n","Epoch 7/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5779 - loss: 23.4054 - val_accuracy: 0.6525 - val_loss: 22.5416\n","Epoch 8/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6033 - loss: 23.1656 - val_accuracy: 0.6525 - val_loss: 22.6089\n","Epoch 9/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6037 - loss: 23.6565 - val_accuracy: 0.6525 - val_loss: 22.6452\n","Epoch 10/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5980 - loss: 23.9143 - val_accuracy: 0.6525 - val_loss: 22.6590\n","Epoch 11/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6072 - loss: 24.0793 - val_accuracy: 0.6525 - val_loss: 22.6743\n","Epoch 12/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5926 - loss: 24.3192 - val_accuracy: 0.6525 - val_loss: 22.6984\n","Epoch 13/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5935 - loss: 23.5293 - val_accuracy: 0.6525 - val_loss: 22.7128\n","Epoch 14/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5911 - loss: 24.3824 - val_accuracy: 0.6525 - val_loss: 22.7312\n","Epoch 15/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6256 - loss: 22.9584 - val_accuracy: 0.6525 - val_loss: 22.7552\n","Epoch 16/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6156 - loss: 23.8089 - val_accuracy: 0.6525 - val_loss: 22.7763\n","Epoch 17/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6255 - loss: 23.3717 - val_accuracy: 0.6525 - val_loss: 22.7927\n","Epoch 18/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6069 - loss: 24.7706 - val_accuracy: 0.6525 - val_loss: 22.7892\n","Epoch 19/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6093 - loss: 24.4313 - val_accuracy: 0.6525 - val_loss: 22.8278\n","Epoch 20/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6148 - loss: 23.2793 - val_accuracy: 0.6525 - val_loss: 22.8697\n","Epoch 21/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5842 - loss: 23.7944 - val_accuracy: 0.6525 - val_loss: 22.8846\n","Epoch 22/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5869 - loss: 23.8791 - val_accuracy: 0.6525 - val_loss: 22.9168\n","Epoch 23/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6099 - loss: 24.6023 - val_accuracy: 0.6525 - val_loss: 22.9339\n","Epoch 24/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5705 - loss: 25.0925 - val_accuracy: 0.6525 - val_loss: 22.9483\n","Epoch 25/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6075 - loss: 23.8262 - val_accuracy: 0.6525 - val_loss: 22.9774\n","Epoch 26/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5749 - loss: 24.9501 - val_accuracy: 0.6525 - val_loss: 22.9936\n","Epoch 27/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6159 - loss: 23.6052 - val_accuracy: 0.6525 - val_loss: 23.0364\n","Epoch 28/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6169 - loss: 24.2464 - val_accuracy: 0.6525 - val_loss: 23.0645\n","Epoch 29/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6117 - loss: 24.0717 - val_accuracy: 0.6525 - val_loss: 23.1004\n","Epoch 30/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5706 - loss: 24.2958 - val_accuracy: 0.6525 - val_loss: 23.1175\n","Epoch 31/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6128 - loss: 24.3321 - val_accuracy: 0.6525 - val_loss: 23.1397\n","Epoch 32/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5843 - loss: 24.3076 - val_accuracy: 0.6525 - val_loss: 23.1458\n","Epoch 33/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5890 - loss: 24.2730 - val_accuracy: 0.6525 - val_loss: 23.1802\n","Epoch 34/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6053 - loss: 24.0813 - val_accuracy: 0.6525 - val_loss: 23.2204\n","Epoch 35/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5816 - loss: 24.3716 - val_accuracy: 0.6525 - val_loss: 23.2771\n","Epoch 36/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5714 - loss: 25.0208 - val_accuracy: 0.6525 - val_loss: 23.2937\n","Epoch 37/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5835 - loss: 25.0974 - val_accuracy: 0.6525 - val_loss: 23.3382\n","Epoch 38/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5888 - loss: 25.1476 - val_accuracy: 0.6525 - val_loss: 23.3780\n","Epoch 39/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5903 - loss: 24.4148 - val_accuracy: 0.6525 - val_loss: 23.4055\n","Epoch 40/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6156 - loss: 25.0183 - val_accuracy: 0.6525 - val_loss: 23.4494\n","Epoch 41/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6195 - loss: 23.1689 - val_accuracy: 0.6525 - val_loss: 23.4886\n","Epoch 42/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5963 - loss: 24.8693 - val_accuracy: 0.6525 - val_loss: 23.5073\n","Epoch 43/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6039 - loss: 24.1096 - val_accuracy: 0.6525 - val_loss: 23.5473\n","Epoch 44/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5726 - loss: 24.2137 - val_accuracy: 0.6525 - val_loss: 23.5782\n","Epoch 45/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5995 - loss: 24.7244 - val_accuracy: 0.6525 - val_loss: 23.6344\n","Epoch 46/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6217 - loss: 24.5051 - val_accuracy: 0.6525 - val_loss: 23.6712\n","Epoch 47/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5993 - loss: 24.2394 - val_accuracy: 0.6525 - val_loss: 23.6846\n","Epoch 48/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5910 - loss: 25.1442 - val_accuracy: 0.6525 - val_loss: 23.7000\n","Epoch 49/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5977 - loss: 24.6295 - val_accuracy: 0.6525 - val_loss: 23.7508\n","Epoch 50/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5828 - loss: 24.9114 - val_accuracy: 0.6525 - val_loss: 23.7900\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6428 - loss: 24.6592 \n","Loss: 23.789997100830078\n","Accuracy: 0.652482271194458\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout\n","from keras.optimizers import Adam\n","\n","# Load dataset\n","data = pd.read_csv('sample_dataset.csv')\n","\n","# Convert date to datetime format\n","data['Date'] = pd.to_datetime(data['Date'])\n","\n","# Extract hour and minute from 'Time' column and combine with date to create a datetime object\n","data['Time'] = pd.to_datetime(data['Time'], format='%H:%M')\n","data['Datetime'] = pd.to_datetime(data['Date'].astype(str) + ' ' + data['Time'].dt.strftime('%H:%M:%S'))\n","\n","# Extract features from datetime\n","data['DayOfWeek'] = data['Datetime'].dt.dayofweek\n","data['Month'] = data['Datetime'].dt.month\n","data['Hour'] = data['Datetime'].dt.hour\n","data['Minute'] = data['Datetime'].dt.minute\n","\n","# Normalize numerical features\n","scaler = MinMaxScaler()\n","data[['DayOfWeek', 'Month', 'Hour', 'Minute']] = scaler.fit_transform(data[['DayOfWeek', 'Month', 'Hour', 'Minute']])\n","\n","# Define features and target\n","X = data[['DayOfWeek', 'Month', 'Hour', 'Minute', 'Location', 'CustomerID']].values\n","y = data[['Fuel_1', 'Fuel_2', 'Fuel_3', 'Fuel_4', 'Fuel_5', 'Fuel_6']].values\n","\n","# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n","\n","# Reshape input data for LSTM (samples, timesteps, features)\n","X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n","X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n","\n","# Define LSTM model architecture\n","model = Sequential()\n","model.add(LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(units=32, return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(units=16))\n","model.add(Dropout(0.2))\n","model.add(Dense(units=6, activation='softmax'))  # Output layer with softmax activation for multi-class classification\n","\n","# Compile the model\n","optimizer = Adam(learning_rate=0.001)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)\n","\n","# Make predictions\n","predictions = model.predict(X_test)\n","\n","# Visualize predictions vs actual values\n","# (You can use classification metrics and confusion matrix for evaluation)\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T08:17:24.303811Z","iopub.status.busy":"2024-04-04T08:17:24.302603Z","iopub.status.idle":"2024-04-04T08:17:24.330047Z","shell.execute_reply":"2024-04-04T08:17:24.328818Z","shell.execute_reply.started":"2024-04-04T08:17:24.303771Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769027e-01, 1.5793043e-01, 4.0080700e-02, 5.8411807e-02,\n","        5.4131551e-03, 4.7360922e-04],\n","       [7.3769027e-01, 1.5793043e-01, 4.0080700e-02, 5.8411807e-02,\n","        5.4131551e-03, 4.7360922e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769009e-01, 1.5793055e-01, 4.0080804e-02, 5.8411852e-02,\n","        5.4131588e-03, 4.7361001e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769027e-01, 1.5793043e-01, 4.0080700e-02, 5.8411807e-02,\n","        5.4131551e-03, 4.7360922e-04],\n","       [7.3769027e-01, 1.5793043e-01, 4.0080700e-02, 5.8411807e-02,\n","        5.4131551e-03, 4.7360922e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769009e-01, 1.5793055e-01, 4.0080804e-02, 5.8411852e-02,\n","        5.4131588e-03, 4.7361001e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769027e-01, 1.5793043e-01, 4.0080778e-02, 5.8411807e-02,\n","        5.4131602e-03, 4.7361013e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769027e-01, 1.5793043e-01, 4.0080700e-02, 5.8411807e-02,\n","        5.4131551e-03, 4.7360922e-04],\n","       [7.3769027e-01, 1.5793043e-01, 4.0080700e-02, 5.8411807e-02,\n","        5.4131551e-03, 4.7360922e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769027e-01, 1.5793043e-01, 4.0080700e-02, 5.8411807e-02,\n","        5.4131551e-03, 4.7360922e-04],\n","       [7.3769027e-01, 1.5793043e-01, 4.0080700e-02, 5.8411807e-02,\n","        5.4131551e-03, 4.7360922e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769045e-01, 1.5793031e-01, 4.0080748e-02, 5.8411822e-02,\n","        5.4131513e-03, 4.7360934e-04],\n","       [7.3769039e-01, 1.5793030e-01, 4.0080745e-02, 5.8411814e-02,\n","        5.4131509e-03, 4.7360928e-04],\n","       [7.3769039e-01, 1.5793030e-01, 4.0080745e-02, 5.8411814e-02,\n","        5.4131509e-03, 4.7360928e-04],\n","       [7.3769039e-01, 1.5793030e-01, 4.0080745e-02, 5.8411814e-02,\n","        5.4131509e-03, 4.7360928e-04],\n","       [7.3769039e-01, 1.5793030e-01, 4.0080745e-02, 5.8411814e-02,\n","        5.4131509e-03, 4.7360928e-04],\n","       [7.3769027e-01, 1.5793043e-01, 4.0080700e-02, 5.8411807e-02,\n","        5.4131551e-03, 4.7360917e-04]], dtype=float32)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["predictions"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T08:24:03.711064Z","iopub.status.busy":"2024-04-04T08:24:03.710595Z","iopub.status.idle":"2024-04-04T08:24:19.720221Z","shell.execute_reply":"2024-04-04T08:24:19.718821Z","shell.execute_reply.started":"2024-04-04T08:24:03.711030Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.2011 - loss: 33.0750 - val_accuracy: 0.6950 - val_loss: 31.3477\n","Epoch 2/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6004 - loss: 31.6517 - val_accuracy: 0.6950 - val_loss: 30.4037\n","Epoch 3/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6403 - loss: 30.5124 - val_accuracy: 0.6950 - val_loss: 28.7353\n","Epoch 4/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6575 - loss: 28.6865 - val_accuracy: 0.6950 - val_loss: 27.5331\n","Epoch 5/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6367 - loss: 28.5518 - val_accuracy: 0.6950 - val_loss: 28.7785\n","Epoch 6/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6532 - loss: 28.7193 - val_accuracy: 0.6950 - val_loss: 30.6188\n","Epoch 7/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6403 - loss: 32.0493 - val_accuracy: 0.6950 - val_loss: 31.4183\n","Epoch 8/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5925 - loss: 34.3017 - val_accuracy: 0.6950 - val_loss: 31.6610\n","Epoch 9/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6412 - loss: 34.2719 - val_accuracy: 0.6950 - val_loss: 31.8243\n","Epoch 10/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6173 - loss: 34.4717 - val_accuracy: 0.6950 - val_loss: 31.9166\n","Epoch 11/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6005 - loss: 32.7730 - val_accuracy: 0.6950 - val_loss: 32.0108\n","Epoch 12/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6606 - loss: 32.7002 - val_accuracy: 0.6950 - val_loss: 32.0999\n","Epoch 13/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6327 - loss: 34.3821 - val_accuracy: 0.6950 - val_loss: 32.1485\n","Epoch 14/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6027 - loss: 34.4824 - val_accuracy: 0.6950 - val_loss: 32.1658\n","Epoch 15/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6414 - loss: 35.7553 - val_accuracy: 0.6950 - val_loss: 32.2164\n","Epoch 16/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6290 - loss: 35.0069 - val_accuracy: 0.6950 - val_loss: 32.2708\n","Epoch 17/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6081 - loss: 34.6174 - val_accuracy: 0.6950 - val_loss: 32.2605\n","Epoch 18/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6264 - loss: 34.8086 - val_accuracy: 0.6950 - val_loss: 32.3061\n","Epoch 19/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6239 - loss: 34.6527 - val_accuracy: 0.6950 - val_loss: 32.3567\n","Epoch 20/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6156 - loss: 35.6161 - val_accuracy: 0.6950 - val_loss: 32.3233\n","Epoch 21/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5822 - loss: 37.2177 - val_accuracy: 0.6950 - val_loss: 32.3450\n","Epoch 22/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6206 - loss: 35.0251 - val_accuracy: 0.6950 - val_loss: 32.4404\n","Epoch 23/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6187 - loss: 35.5505 - val_accuracy: 0.6950 - val_loss: 32.4443\n","Epoch 24/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5966 - loss: 35.2616 - val_accuracy: 0.6950 - val_loss: 32.4753\n","Epoch 25/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6183 - loss: 34.7723 - val_accuracy: 0.6950 - val_loss: 32.5077\n","Epoch 26/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6225 - loss: 36.0611 - val_accuracy: 0.6950 - val_loss: 32.5500\n","Epoch 27/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6061 - loss: 36.2653 - val_accuracy: 0.6950 - val_loss: 32.5519\n","Epoch 28/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6297 - loss: 35.2301 - val_accuracy: 0.6950 - val_loss: 32.6295\n","Epoch 29/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6104 - loss: 34.3028 - val_accuracy: 0.6950 - val_loss: 32.6492\n","Epoch 30/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6173 - loss: 35.5106 - val_accuracy: 0.6950 - val_loss: 32.6660\n","Epoch 31/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6145 - loss: 35.0311 - val_accuracy: 0.6950 - val_loss: 32.7204\n","Epoch 32/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6410 - loss: 33.2980 - val_accuracy: 0.6950 - val_loss: 32.8012\n","Epoch 33/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6552 - loss: 33.6504 - val_accuracy: 0.6950 - val_loss: 32.8238\n","Epoch 34/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6293 - loss: 34.6006 - val_accuracy: 0.6950 - val_loss: 32.8098\n","Epoch 35/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6649 - loss: 35.2037 - val_accuracy: 0.6950 - val_loss: 32.8512\n","Epoch 36/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6322 - loss: 34.5948 - val_accuracy: 0.6950 - val_loss: 32.8811\n","Epoch 37/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6343 - loss: 35.0209 - val_accuracy: 0.6950 - val_loss: 32.8758\n","Epoch 38/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6208 - loss: 34.9255 - val_accuracy: 0.6950 - val_loss: 32.9467\n","Epoch 39/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6457 - loss: 35.4469 - val_accuracy: 0.6950 - val_loss: 32.9549\n","Epoch 40/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6609 - loss: 34.2243 - val_accuracy: 0.6950 - val_loss: 32.9889\n","Epoch 41/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6155 - loss: 38.0338 - val_accuracy: 0.6950 - val_loss: 32.9892\n","Epoch 42/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6079 - loss: 36.0215 - val_accuracy: 0.6950 - val_loss: 33.0381\n","Epoch 43/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6288 - loss: 34.8977 - val_accuracy: 0.6950 - val_loss: 33.0851\n","Epoch 44/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6403 - loss: 33.5622 - val_accuracy: 0.6950 - val_loss: 33.1264\n","Epoch 45/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6567 - loss: 34.7375 - val_accuracy: 0.6950 - val_loss: 33.1403\n","Epoch 46/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6309 - loss: 37.0728 - val_accuracy: 0.6950 - val_loss: 33.1438\n","Epoch 47/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6459 - loss: 34.2828 - val_accuracy: 0.6950 - val_loss: 33.1810\n","Epoch 48/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6170 - loss: 35.1643 - val_accuracy: 0.6950 - val_loss: 33.2083\n","Epoch 49/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6148 - loss: 35.8774 - val_accuracy: 0.6950 - val_loss: 33.2504\n","Epoch 50/50\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6326 - loss: 37.0472 - val_accuracy: 0.6950 - val_loss: 33.2403\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6900 - loss: 34.5273 \n","Loss: 33.24028778076172\n","Accuracy: 0.695035457611084\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout\n","from keras.optimizers import Adam\n","\n","# Load dataset\n","data = pd.read_csv('sample_dataset.csv')\n","\n","# Convert date to datetime format\n","data['Date'] = pd.to_datetime(data['Date'])\n","\n","# Extract hour and minute from 'Time' column and combine with date to create a datetime object\n","data['Time'] = pd.to_datetime(data['Time'], format='%H:%M')\n","data['Datetime'] = pd.to_datetime(data['Date'].astype(str) + ' ' + data['Time'].dt.strftime('%H:%M:%S'))\n","\n","# Extract features from datetime\n","data['DayOfWeek'] = data['Datetime'].dt.dayofweek\n","data['Month'] = data['Datetime'].dt.month\n","data['Hour'] = data['Datetime'].dt.hour\n","data['Minute'] = data['Datetime'].dt.minute\n","\n","# Normalize numerical features\n","scaler = MinMaxScaler()\n","data[['DayOfWeek', 'Month', 'Hour', 'Minute']] = scaler.fit_transform(data[['DayOfWeek', 'Month', 'Hour', 'Minute']])\n","\n","# Define features and target\n","X = data[['DayOfWeek', 'Month', 'Hour', 'Minute', 'Location', 'CustomerID']].values\n","y = data[['Fuel_1', 'Fuel_2', 'Fuel_3', 'Fuel_4', 'Fuel_5', 'Fuel_6']].values\n","\n","# Ensure fuel amounts are multiples of 3 or 4\n","y = np.round(y / 3) * 3\n","\n","# Calculate total fuel amounts\n","total_fuel = np.sum(y, axis=1)\n","\n","# Define target total fuel values (either 12 or 24, whichever is closer)\n","target_total_fuel = np.where(total_fuel < 18, 12, 24)\n","\n","# Adjust predictions to meet total fuel constraints\n","for i in range(len(y)):\n","    excess_fuel = np.abs(total_fuel[i] - target_total_fuel[i])\n","    while excess_fuel > 0:\n","        if total_fuel[i] < target_total_fuel[i]:\n","            # Increase one of the fuel types by 3 or 4 to meet the target\n","            fuel_idx = np.random.choice(np.where(y[i] % 3 == 0)[0])\n","            y[i][fuel_idx] += 3\n","            excess_fuel -= 3\n","        else:\n","            # Decrease one of the fuel types by 3 or 4 to meet the target\n","            fuel_idx = np.random.choice(np.where(y[i] % 3 == 0)[0])\n","            y[i][fuel_idx] -= 3\n","            excess_fuel -= 3\n","\n","# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n","\n","# Reshape input data for LSTM (samples, timesteps, features)\n","X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n","X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n","\n","# Define LSTM model architecture for classification\n","model = Sequential()\n","model.add(LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(units=32, return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(units=16))\n","model.add(Dropout(0.2))\n","model.add(Dense(units=6, activation='softmax'))  # Output layer with softmax activation for multi-class classification\n","\n","# Compile the model\n","optimizer = Adam(learning_rate=0.001)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)\n","\n","# Make predictions\n","predictions = model.predict(X_test)\n","\n","# Round the predictions to the nearest multiples of 3 or 4\n","predictions = np.round(predictions / 3) * 3\n","\n","# Visualize predictions vs actual values\n","# (You can use classification metrics and confusion matrix for evaluation)\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T08:30:22.697560Z","iopub.status.busy":"2024-04-04T08:30:22.697033Z","iopub.status.idle":"2024-04-04T08:30:22.716091Z","shell.execute_reply":"2024-04-04T08:30:22.714493Z","shell.execute_reply.started":"2024-04-04T08:30:22.697521Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.]], dtype=float32)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["predictions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["                                                  \n","    "]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4730147,"sourceId":8026183,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
